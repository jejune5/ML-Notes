{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy.data import get_tokenizer\n",
    "from torchtext.legacy.vocab import Vocab, build_vocab_from_iterator\n",
    "from torch.utils.data import Dataset\n",
    "import unicodedata\n",
    "import opencc\n",
    "import os\n",
    "\n",
    "from config import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n定义超参\\n'"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "定义超参\n",
    "\"\"\"\n",
    "# MAX_LENGTH = 20\n",
    "# PROJECT_ROOT_PATH = os.path.abspath('.') + os.path.sep + os.path.join('..', '..')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "简体 -> 繁体\n",
    "\"\"\"\n",
    "cc = opencc.OpenCC('t2s')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "将 unicode -> ASCII\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def unicodeToAscii(s: str):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                   if unicodedata.category(c) != 'Mn')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "过滤长句\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0]) < MAX_LENGTH and len(p[1]) < MAX_LENGTH\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "分词\n",
    "\"\"\"\n",
    "\n",
    "token_transform_en = get_tokenizer(tokenizer='spacy', language='en_core_web_sm')\n",
    "token_transform_zh = get_tokenizer(tokenizer='spacy', language='zh_core_web_sm')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.pairs = []\n",
    "        for line in open(path, encoding='utf-8'):\n",
    "            pair = cc.convert(line).split('\\t')\n",
    "            pair[0] = token_transform_en(unicodeToAscii(pair[0].lower().strip()))\n",
    "            pair[1] = token_transform_zh(unicodeToAscii(pair[1].lower().strip()))\n",
    "            pair.pop()\n",
    "            if filterPair(pair):\n",
    "                self.pairs.append(pair)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.pairs[idx][0], self.pairs[idx][1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "\n",
    "# MyData(path=os.path.join(PROJECT_ROOT_PATH, 'data', 'cmn-eng', 'cmn.txt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "token 迭代器\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def yield_tokens(data_iter, id: int):\n",
    "    for data_sample in data_iter:\n",
    "        yield data_sample[id]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "vocab 生成\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def vocab_generate():\n",
    "    data = MyData(path=os.path.join(PROJECT_ROOT_PATH, 'data', 'cmn-eng', 'cmn.txt'))\n",
    "    eng = build_vocab_from_iterator(yield_tokens(data_iter=data, id=0), )\n",
    "    zh = build_vocab_from_iterator(yield_tokens(data_iter=data, id=1), )\n",
    "    return data, eng, zh\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28394lines [00:00, 650383.74lines/s]\n",
      "28394lines [00:00, 610956.13lines/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "实现vocab\n",
    "\"\"\"\n",
    "data, eng, zh = vocab_generate()\n",
    "# CMN_ENG_PATH = os.path.join(PROJECT_ROOT_PATH, 'Example', 'CMN-ENG')\n",
    "torch.save(eng, os.path.join(vocab_path, \"en_vocab\"))\n",
    "torch.save(zh, os.path.join(vocab_path, \"zh_vocab\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "([1525, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2])"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence2index(sentence: list, vocab, MAX_LENGTH) -> (list, list):\n",
    "    index = []\n",
    "    if len(sentence) < MAX_LENGTH:\n",
    "        valid_len = [len(sentence)]\n",
    "        sentence += ['<pad>'] * (MAX_LENGTH - len(sentence))\n",
    "    else:\n",
    "        valid_len = [MAX_LENGTH]\n",
    "        sentence = sentence[:MAX_LENGTH]\n",
    "    for token in sentence:\n",
    "        if token not in vocab.stoi:\n",
    "            token = '<unk>'\n",
    "        index.append(vocab.stoi[token])\n",
    "    return index, valid_len\n",
    "\n",
    "\n",
    "sentence = ['hi', '.']\n",
    "vocab = eng\n",
    "sentence2index(sentence, vocab, 20)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# eng.\n",
    "# eng.stoi\n",
    "# eng.itos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "\n",
    "# 生成语料\n",
    "def load_corpus(data, eng_vocab, zh_vocab, MAX_LENGTH=MAX_LENGTH):\n",
    "    sentence = []\n",
    "    valid_len = []\n",
    "    for en_lang, zh_lang in data.pairs:\n",
    "        en_index, en_valid_len = sentence2index(en_lang, eng_vocab, MAX_LENGTH)\n",
    "        zh_index, zh_valid_len = sentence2index(zh_lang, zh_vocab, MAX_LENGTH)\n",
    "        sentence.append([en_index, zh_index])\n",
    "        valid_len.append([en_valid_len, zh_valid_len])\n",
    "    return sentence, valid_len\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\REPO\\github\\ML-Notes\\Example\\CMN-ENG\\..\\..\\Example\\CMN-ENG\\corpus\n",
      "[[[1525, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2425, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], [[1525, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1242, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], [[529, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [6, 111, 388, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]] [[[2], [2]], [[2], [2]], [[2], [5]]]\n",
      "torch.Size([28394, 2, 20])\n",
      "torch.Size([28394, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "print(corpus_path)\n",
    "\n",
    "sentence, valid_len = load_corpus(data, eng, zh)\n",
    "\n",
    "print(sentence[:3], valid_len[:3])\n",
    "sentence = torch.tensor(sentence, dtype=torch.long)\n",
    "valid_len = torch.tensor(valid_len, dtype=torch.long)\n",
    "torch.save(sentence, os.path.join(corpus_path, 'sentence'))\n",
    "torch.save(valid_len, os.path.join(corpus_path, 'valid_len'))\n",
    "print(sentence.shape)\n",
    "print(valid_len.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}