{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "from d2l.torch import d2l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2seqEncoder(d2l.Encoder):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs):\n",
    "        super(seq2seqEncoder, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers, dropout=dropout)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        X = self.embedding(X)\n",
    "        X = X.permute(1, 0, 2)\n",
    "        output, state = self.rnn(X)\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([7, 4, 16]), torch.Size([2, 4, 16]))"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = seq2seqEncoder(vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2)\n",
    "encoder.eval()\n",
    "\n",
    "X = torch.zeros((4, 7), dtype=torch.long)\n",
    "output, state = encoder(X)\n",
    "output.shape, state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (4, 7)  torch.Size([4, 7])\n",
      "X ebd [7, 4, 8] torch.Size([7, 4, 8])\n",
      "state[-1] (4, 16) torch.Size([4, 16])\n",
      "contxt (7, 4, 16) torch.Size([7, 4, 16])\n",
      "X_and_context (7, 4, 24) torch.Size([7, 4, 24])\n",
      "output (7, 4, 16) torch.Size([7, 4, 16])\n",
      "fc output (7, 4, 10) torch.Size([7, 4, 10])\n",
      "permute output (4, 7, 10) torch.Size([4, 7, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": "(torch.Size([4, 7, 10]), torch.Size([2, 4, 16]))"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Seq2SeqDecoder(d2l.Decoder):\n",
    "    \"\"\"用于序列到序列学习的循环神经网络解码器\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqDecoder, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers,\n",
    "                          dropout=dropout)\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        return enc_outputs[1]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        # 输出'X'的形状：(batch_size,num_steps,embed_size)\n",
    "        X = self.embedding(X).permute(1, 0, 2)\n",
    "        # 广播context，使其具有与X相同的num_steps\n",
    "        print('X ebd [7, 4, 8]', X.shape)\n",
    "        print('state[-1] (4, 16)', state[-1].shape)\n",
    "        context = state[-1].repeat(X.shape[0], 1, 1)\n",
    "        print('contxt (7, 4, 16)', context.shape)\n",
    "\n",
    "        X_and_context = torch.cat((X, context), 2)\n",
    "        print('X_and_context (7, 4, 24)', X_and_context.shape)\n",
    "        output, state = self.rnn(X_and_context, state)\n",
    "        print('output (7, 4, 16)', output.shape)\n",
    "        output = self.dense(output)\n",
    "        print('fc output (7, 4, 10)', output.shape)\n",
    "        output = output.permute(1, 0, 2)\n",
    "        print('permute output (4, 7, 10)', output.shape)\n",
    "        # output的形状:(batch_size,num_steps,vocab_size)\n",
    "        # state[0]的形状:(num_layers,batch_size,num_hiddens)\n",
    "        return output, state\n",
    "\n",
    "\n",
    "print('X (4, 7) ', X.shape)\n",
    "decoder = Seq2SeqDecoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                         num_layers=2)\n",
    "decoder.eval()\n",
    "state = decoder.init_state(encoder(X))\n",
    "#\n",
    "# print(state.shape)\n",
    "output, state = decoder(X, state)\n",
    "output.shape, state.shape\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8415834e63a09e6b568761fadaaf012b2f6c5d86989cdbeae6807bb85c1f6f7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}