{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "path_to_file = r'D:\\REPO\\github\\ML-Notes\\Competition\\天池-NLP-新闻文本分类\\data\\test_a.csv'\n",
    "df = pd.read_csv(path_to_file)\n",
    "df = df.head(1000)\n",
    "\n",
    "with open('./text.txt', 'w') as f:\n",
    "    for setence in df.text.values:\n",
    "        f.write(setence + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. 快速生成tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-chinese/resolve/main/vocab.txt from cache at C:\\Users\\Jejune/.cache\\huggingface\\transformers\\36acdf4f3edf0a14ffb2b2c68ba47e93abd9448825202377ddb16dae8114fe07.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
      "loading file https://huggingface.co/bert-base-chinese/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-chinese/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-chinese/resolve/main/tokenizer_config.json from cache at C:\\Users\\Jejune/.cache\\huggingface\\transformers\\2dc6085404c55008ba7fc09ab7483ef3f0a4ca2496ccee0cdbf51c2b5d529dff.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-chinese/resolve/main/config.json from cache at C:\\Users\\Jejune/.cache\\huggingface\\transformers\\6cc404ca8136bc87bae0fb24f2259904943d776a6c5ddc26598bbdc319476f42.0f9bcd8314d841c06633e7b92b04509f1802c16796ee67b0f1177065739e24ae\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "Creating features from dataset file at text.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of lines:  1000\n"
     ]
    }
   ],
   "source": [
    "# Train a tokenizer\n",
    "import tokenizers\n",
    "from transformers import BertTokenizer, LineByLineTextDataset\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "dataset= LineByLineTextDataset(\n",
    "    tokenizer = tokenizer,\n",
    "    file_path = 'text.txt',\n",
    "    block_size = 64  # maximum sequence length\n",
    ")\n",
    "\n",
    "print('No. of lines: ', len(dataset)) # No of lines in your datset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '今', '天', '天', '气', '怎', '么', '样', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"今天天气怎么样\"\n",
    "tokens = ['[CLS]'] + tokenizer.tokenize(sentence) + ['[SEP]']\n",
    "print(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.定义 Bert-base\n",
    "12 12 768\n",
    "- 预测掩码词的数量 选择15%要预测的随机词元\n",
    "- DataCollatorForLanguageModeling API即可方便得以自己的语料定义生成器"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数数量: 89887880\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertForMaskedLM, DataCollatorForLanguageModeling\n",
    "\n",
    "config = BertConfig(\n",
    "    vocab_size=5000,\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    max_position_embeddings=512,\n",
    ")\n",
    "model = BertForMaskedLM(config)\n",
    "print('参数数量:', model.num_parameters())\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.定义训练参数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_23536/2553761222.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m )\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m trainer = Trainer(\n\u001B[0m\u001B[0;32m     13\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[0margs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtraining_args\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\python38\\lib\\site-packages\\transformers\\trainer.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001B[0m\n\u001B[0;32m    297\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    298\u001B[0m         \u001B[1;31m# Seed must be set before instantiating the model when using model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 299\u001B[1;33m         \u001B[0mset_seed\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mseed\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    300\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhp_name\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    301\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdeepspeed\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\python38\\lib\\site-packages\\transformers\\trainer_utils.py\u001B[0m in \u001B[0;36mset_seed\u001B[1;34m(seed)\u001B[0m\n\u001B[0;32m     57\u001B[0m     \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mseed\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mseed\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mis_torch_available\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmanual_seed\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mseed\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     60\u001B[0m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmanual_seed_all\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mseed\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m         \u001B[1;31m# ^^ safe to call this function even if cuda is not available\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\python38\\lib\\site-packages\\torch\\random.py\u001B[0m in \u001B[0;36mmanual_seed\u001B[1;34m(seed)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_is_in_bad_fork\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 40\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmanual_seed_all\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mseed\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     41\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mdefault_generator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmanual_seed\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mseed\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\python38\\lib\\site-packages\\torch\\cuda\\random.py\u001B[0m in \u001B[0;36mmanual_seed_all\u001B[1;34m(seed)\u001B[0m\n\u001B[0;32m    111\u001B[0m             \u001B[0mdefault_generator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmanual_seed\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mseed\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 113\u001B[1;33m     \u001B[0m_lazy_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mseed_all\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    114\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\python38\\lib\\site-packages\\torch\\cuda\\__init__.py\u001B[0m in \u001B[0;36m_lazy_call\u001B[1;34m(callable, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0m_lazy_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcallable\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mis_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 153\u001B[1;33m         \u001B[0mcallable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    154\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    155\u001B[0m         \u001B[1;31m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\python38\\lib\\site-packages\\torch\\cuda\\random.py\u001B[0m in \u001B[0;36mcb\u001B[1;34m()\u001B[0m\n\u001B[0;32m    109\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    110\u001B[0m             \u001B[0mdefault_generator\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdefault_generators\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 111\u001B[1;33m             \u001B[0mdefault_generator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmanual_seed\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mseed\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    112\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    113\u001B[0m     \u001B[0m_lazy_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mseed_all\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=30,\n",
    "    per_device_train_batch_size=64,\n",
    "    save_steps=10000,\n",
    "    # save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model('./')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}