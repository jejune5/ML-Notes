{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,optimizers,datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(60000, 28, 28) (60000, 10) --> (10000, 28, 28) (10000,)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 1 准备数据\n",
    "(x,y), (x_val,y_val) = datasets.mnist.load_data()\n",
    "#转化到浮点，并缩放到 [-1,1]\n",
    "x = 2*tf.convert_to_tensor(x,dtype=tf.float32)/255. - 1\n",
    "#转换为整形张量\n",
    "y = tf.convert_to_tensor(y,dtype = tf.int32) \n",
    "y = tf.one_hot(y,depth=10)#one-hot编码\n",
    "print(x.shape,y.shape,'-->',x_val.shape,y_val.shape)\n",
    "#构建数据集对象\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "#批量训练\n",
    "train_dataset = train_dataset.batch(512)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 2 网络搭建\n",
    "# 创建一层网络，设置输出节点数为256，激活函数类型为ReLU\n",
    "layers.Dense(256, activation='relu')\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # 隐藏层 1\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    # 隐藏层 2\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    # 输出层\n",
    "    layers.Dense(10)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-df91bd27ed0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# [b] => [b, 10]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0my_onehot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m#计算差的平方和, [b,10]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_onehot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\pro\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\pro\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[1;34m(indices, depth, on_value, off_value, axis, dtype, name)\u001b[0m\n\u001b[0;32m   3643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3644\u001b[0m     return gen_array_ops.one_hot(indices, depth, on_value, off_value, axis,\n\u001b[1;32m-> 3645\u001b[1;33m                                  name)\n\u001b[0m\u001b[0;32m   3646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\pro\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[1;34m(indices, depth, on_value, off_value, axis, name)\u001b[0m\n\u001b[0;32m   5547\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5548\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5549\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5550\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5551\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\pro\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6605\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6606\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6607\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\pro\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Could not find valid device for node.\nNode:{{node OneHot}}\nAll kernels registered for op OneHot :\n  device='GPU'; TI in [DT_UINT8]; T in [DT_HALF]\n  device='GPU'; TI in [DT_INT32]; T in [DT_HALF]\n  device='GPU'; TI in [DT_INT64]; T in [DT_HALF]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_FLOAT]\n  device='GPU'; TI in [DT_INT32]; T in [DT_FLOAT]\n  device='GPU'; TI in [DT_INT64]; T in [DT_FLOAT]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_DOUBLE]\n  device='GPU'; TI in [DT_INT32]; T in [DT_DOUBLE]\n  device='GPU'; TI in [DT_INT64]; T in [DT_DOUBLE]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_BOOL]\n  device='GPU'; TI in [DT_INT32]; T in [DT_BOOL]\n  device='GPU'; TI in [DT_INT64]; T in [DT_BOOL]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_INT32]\n  device='GPU'; TI in [DT_INT32]; T in [DT_INT32]\n  device='GPU'; TI in [DT_INT64]; T in [DT_INT32]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_INT64]\n  device='GPU'; TI in [DT_INT32]; T in [DT_INT64]\n  device='GPU'; TI in [DT_INT64]; T in [DT_INT64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT64]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT64]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT32]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT32]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT32]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_INT32]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_INT64]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT8]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT8]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT8]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_HALF]\n  device='CPU'; TI in [DT_INT32]; T in [DT_HALF]\n  device='CPU'; TI in [DT_INT64]; T in [DT_HALF]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_INT32]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_INT64]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_INT32]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_INT64]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_INT32]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_INT64]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_INT32]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_INT64]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_INT32]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_INT64]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_STRING]\n  device='CPU'; TI in [DT_INT32]; T in [DT_STRING]\n  device='CPU'; TI in [DT_INT64]; T in [DT_STRING]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_INT32]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_INT64]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_VARIANT]\n  device='CPU'; TI in [DT_INT32]; T in [DT_VARIANT]\n  device='CPU'; TI in [DT_INT64]; T in [DT_VARIANT]\n [Op:OneHot] name: one_hot/"
     ],
     "ename": "NotFoundError",
     "evalue": "Could not find valid device for node.\nNode:{{node OneHot}}\nAll kernels registered for op OneHot :\n  device='GPU'; TI in [DT_UINT8]; T in [DT_HALF]\n  device='GPU'; TI in [DT_INT32]; T in [DT_HALF]\n  device='GPU'; TI in [DT_INT64]; T in [DT_HALF]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_FLOAT]\n  device='GPU'; TI in [DT_INT32]; T in [DT_FLOAT]\n  device='GPU'; TI in [DT_INT64]; T in [DT_FLOAT]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_DOUBLE]\n  device='GPU'; TI in [DT_INT32]; T in [DT_DOUBLE]\n  device='GPU'; TI in [DT_INT64]; T in [DT_DOUBLE]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_BOOL]\n  device='GPU'; TI in [DT_INT32]; T in [DT_BOOL]\n  device='GPU'; TI in [DT_INT64]; T in [DT_BOOL]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_INT32]\n  device='GPU'; TI in [DT_INT32]; T in [DT_INT32]\n  device='GPU'; TI in [DT_INT64]; T in [DT_INT32]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_INT64]\n  device='GPU'; TI in [DT_INT32]; T in [DT_INT64]\n  device='GPU'; TI in [DT_INT64]; T in [DT_INT64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT64]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT64]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT32]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT32]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT32]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_INT32]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_INT64]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT8]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT8]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT8]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_HALF]\n  device='CPU'; TI in [DT_INT32]; T in [DT_HALF]\n  device='CPU'; TI in [DT_INT64]; T in [DT_HALF]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_INT32]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_INT64]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_INT32]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_INT64]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_INT32]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_INT64]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_INT32]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_INT64]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_INT32]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_INT64]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_STRING]\n  device='CPU'; TI in [DT_INT32]; T in [DT_STRING]\n  device='CPU'; TI in [DT_INT64]; T in [DT_STRING]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_INT32]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_INT64]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_VARIANT]\n  device='CPU'; TI in [DT_INT32]; T in [DT_VARIANT]\n  device='CPU'; TI in [DT_INT64]; T in [DT_VARIANT]\n [Op:OneHot] name: one_hot/",
     "output_type": "error"
    }
   ],
   "source": [
    "# 3 训练模型\n",
    "# 构建梯度记录环境\n",
    "with tf.GradientTape() as tape:\n",
    "    # 打平操作, [b,28,28] => [b,784]\n",
    "    x = tf.reshape(x,(-1, 28*28))\n",
    "    # Step1 得到模型的输出output [b,784] =>[b,10]\n",
    "    out = model(x)\n",
    "    # [b] => [b, 10]\n",
    "    y_onehot = tf.one_hot(y, depth=10)\n",
    "    #计算差的平方和, [b,10]\n",
    "    loss = tf.square(out - y_onehot)\n",
    "    # 计算每个样本的平均误差, [b]\n",
    "    loss = tf.reduce_sum(loss) / x.shape\n",
    "    # Step3 计算参数的梯度 w1、w2、w3、b1、b2、b3\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizers.apply_gradients(zip(grads,model.trainable_variables))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}